{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guia ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#https://jdvelasq.github.io/courses/notebooks/pyspark/2-04-pyspark-SparkSQL.html\n",
    "#https://guru99.es/pyspark-tutorial/\n",
    "## findspark permite usar pyspark (interfaz de Python a Spark),\n",
    "## desde cualquier programa escrito en Python.\n",
    "##\n",
    "import findspark\n",
    "findspark.init()\n",
    "##\n",
    "## A continuación se inicializan las variables obligatorias\n",
    "## requeridas para trabajar con Spark desde Python:\n",
    "##\n",
    "##  SparkContext representa la conexión al cluster de Spark.\n",
    "##  SparkConf representa la configuración particular de una aplicación\n",
    "##     escrita en Spark.\n",
    "##  SparkSession representa la conexión para trabajar con SQL.\n",
    "##\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sparkConf = SparkConf().setAppName(\"ml_spark\")\n",
    "sc = SparkContext(conf=sparkConf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- estu_edad: double (nullable = true)\n",
      " |-- estu_nacimiento_dia: double (nullable = true)\n",
      " |-- estu_nacimiento_mes: double (nullable = true)\n",
      " |-- estu_nacimiento_anno: double (nullable = true)\n",
      " |-- estu_zona_reside: double (nullable = true)\n",
      " |-- estu_area_reside: double (nullable = true)\n",
      " |-- cole_valor_pension: double (nullable = true)\n",
      " |-- estu_trabaja: double (nullable = true)\n",
      " |-- fami_estrato_vivienda: double (nullable = true)\n",
      " |-- estu_veces_estado: double (nullable = true)\n",
      " |-- fami_educa_padre: double (nullable = true)\n",
      " |-- fami_educa_madre: double (nullable = true)\n",
      " |-- fami_ocup_padre: double (nullable = true)\n",
      " |-- fami_ocup_madre: double (nullable = true)\n",
      " |-- fami_nivel_sisben: double (nullable = true)\n",
      " |-- fami_pisos_hogar: double (nullable = true)\n",
      " |-- fami_personas_hogar: double (nullable = true)\n",
      " |-- fami_telefono_fijo: double (nullable = true)\n",
      " |-- fami_celular: double (nullable = true)\n",
      " |-- fami_internet: double (nullable = true)\n",
      " |-- fami_servicio_television: double (nullable = true)\n",
      " |-- fami_computador: double (nullable = true)\n",
      " |-- fami_lavadora: double (nullable = true)\n",
      " |-- fami_nevera: double (nullable = true)\n",
      " |-- fami_horno: double (nullable = true)\n",
      " |-- fami_dvd: double (nullable = true)\n",
      " |-- fami_microondas: double (nullable = true)\n",
      " |-- fami_automovil: double (nullable = true)\n",
      " |-- fami_ing_fmiliar_mensual: double (nullable = true)\n",
      " |-- estu_anos_preescolar: double (nullable = true)\n",
      " |-- estu_reprobo_primero: double (nullable = true)\n",
      " |-- estu_anos_colegio_actual: double (nullable = true)\n",
      " |-- estu_cuantos_cole_estudio: double (nullable = true)\n",
      " |-- estu_razon_retiro: double (nullable = true)\n",
      " |-- estu_total_alumnos_curso: double (nullable = true)\n",
      " |-- estu_prestigioinstitucion: double (nullable = true)\n",
      " |-- estu_por_ubicacion: double (nullable = true)\n",
      " |-- estu_por_unicaqueofrece: double (nullable = true)\n",
      " |-- estu_por_amigosestudiando: double (nullable = true)\n",
      " |-- estu_por_otrarazon: double (nullable = true)\n",
      " |-- estu_por_orientacionvocacional: double (nullable = true)\n",
      " |-- estu_por_tradicionfamiliar: double (nullable = true)\n",
      " |-- estu_por_influenciaalguien: double (nullable = true)\n",
      " |-- cole_bilingue: double (nullable = true)\n",
      " |-- prom_puntaje: double (nullable = true)\n",
      " |-- clase: integer (nullable = true)\n",
      " |-- estu_genero_f: integer (nullable = true)\n",
      " |-- cole_calendario_a: integer (nullable = true)\n",
      " |-- cole_genero_x: integer (nullable = true)\n",
      " |-- cole_naturaleza_o: integer (nullable = true)\n",
      " |-- cole_jornada_manana: integer (nullable = true)\n",
      " |-- cole_jornada_tarde: integer (nullable = true)\n",
      " |-- cole_jornada_noche: integer (nullable = true)\n",
      " |-- cole_caracter_tecnico: integer (nullable = true)\n",
      " |-- cole_caracter_acaemico: integer (nullable = true)\n",
      " |-- cole_caracter_normalista: integer (nullable = true)\n",
      " |-- cole_nombre_sede_col_los_amigos_de_la_ciencia: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_tangareal_carretera: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_general_santander: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_ciudadela_mixta_colombia: integer (nullable = true)\n",
      " |-- cole_nombre_sede_inst_vigotsky: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_ciudadela_educativa_tumac: integer (nullable = true)\n",
      " |-- cole_nombre_sede_ie_manuel_elkin_patarrollo: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_imbili_carretera: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_san_luis_robles: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_san_jose_de_caunapi: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_liceo_nacional_max_seidel: integer (nullable = true)\n",
      " |-- cole_nombre_sede_institucion__educativa_colorado: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_misional_santa_teresita: integer (nullable = true)\n",
      " |-- cole_nombre_sede_liceo_san_andres: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_santa_teresita: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_dos_quebradas: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_manuel_benitez_duclerg: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_4_bucheli: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_iberia: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_luis_antonio_rojas_cruz: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_inmaculada_concepcion: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_inst_tec_industrial_nal_tumaco: integer (nullable = true)\n",
      " |-- cole_nombre_sede_institucion_educativa_nuevo_horizonte: integer (nullable = true)\n",
      " |-- cole_nombre_sede_i_e_roberto_mario_bischoff_-_sede_principal: integer (nullable = true)\n",
      " |-- cole_nombre_sede_instituto_gabriel_garcia_marquez: integer (nullable = true)\n",
      " |-- cole_nombre_sede_ie_llorente_-_sede_princiapl: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_faustino_arias_reinel: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_san_juan_evangelista: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_chilvi: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_inst_tec__popular_de_la_costa: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_5_colorado: integer (nullable = true)\n",
      " |-- cole_nombre_sede_inst_mixto_renacer: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_nuestra_señora_de_fatima: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_la_florida: integer (nullable = true)\n",
      " |-- cole_nombre_sede_col_rafael_pombo: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_chajal: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Row representa una fila en un RDD\n",
    "##\n",
    "from pyspark.sql import Row\n",
    "##\n",
    "## Crea un DataFrame a partir del archivo con\n",
    "## formato CSV\n",
    "##\n",
    "df_ml = spark.read.load(\"D:\\\\CLASES\\ELECTIVA 3 BigData\\\\Clase5_Ejercicos_Spark\\\\DATOS\\\\data_icfes_ml_tumaco.csv\",\n",
    "                     format=\"csv\",\n",
    "                     sep=\"|\",\n",
    "                     inferSchema= True,\n",
    "                     encoding=\"utf-8\",\n",
    "                     header=\"true\")\n",
    "df_ml.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1923"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ml.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupar datos por clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|clase|count(1)|\n",
      "+-----+--------+\n",
      "|    1|     331|\n",
      "|    0|    1592|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ml.createOrReplaceTempView(\"icfes_ml\")\n",
    "spark.sql(\"select clase,count(1) from icfes_ml group by clase\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- estu_edad: double (nullable = true)\n",
      " |-- estu_nacimiento_dia: double (nullable = true)\n",
      " |-- estu_nacimiento_mes: double (nullable = true)\n",
      " |-- estu_nacimiento_anno: double (nullable = true)\n",
      " |-- estu_zona_reside: double (nullable = true)\n",
      " |-- estu_area_reside: double (nullable = true)\n",
      " |-- cole_valor_pension: double (nullable = true)\n",
      " |-- estu_trabaja: double (nullable = true)\n",
      " |-- fami_estrato_vivienda: double (nullable = true)\n",
      " |-- estu_veces_estado: double (nullable = true)\n",
      " |-- fami_educa_padre: double (nullable = true)\n",
      " |-- fami_educa_madre: double (nullable = true)\n",
      " |-- fami_ocup_padre: double (nullable = true)\n",
      " |-- fami_ocup_madre: double (nullable = true)\n",
      " |-- fami_nivel_sisben: double (nullable = true)\n",
      " |-- fami_pisos_hogar: double (nullable = true)\n",
      " |-- fami_personas_hogar: double (nullable = true)\n",
      " |-- fami_telefono_fijo: double (nullable = true)\n",
      " |-- fami_celular: double (nullable = true)\n",
      " |-- fami_internet: double (nullable = true)\n",
      " |-- fami_servicio_television: double (nullable = true)\n",
      " |-- fami_computador: double (nullable = true)\n",
      " |-- fami_lavadora: double (nullable = true)\n",
      " |-- fami_nevera: double (nullable = true)\n",
      " |-- fami_horno: double (nullable = true)\n",
      " |-- fami_dvd: double (nullable = true)\n",
      " |-- fami_microondas: double (nullable = true)\n",
      " |-- fami_automovil: double (nullable = true)\n",
      " |-- fami_ing_fmiliar_mensual: double (nullable = true)\n",
      " |-- estu_anos_preescolar: double (nullable = true)\n",
      " |-- estu_reprobo_primero: double (nullable = true)\n",
      " |-- estu_anos_colegio_actual: double (nullable = true)\n",
      " |-- estu_cuantos_cole_estudio: double (nullable = true)\n",
      " |-- estu_razon_retiro: double (nullable = true)\n",
      " |-- estu_total_alumnos_curso: double (nullable = true)\n",
      " |-- estu_prestigioinstitucion: double (nullable = true)\n",
      " |-- estu_por_ubicacion: double (nullable = true)\n",
      " |-- estu_por_unicaqueofrece: double (nullable = true)\n",
      " |-- estu_por_amigosestudiando: double (nullable = true)\n",
      " |-- estu_por_otrarazon: double (nullable = true)\n",
      " |-- estu_por_orientacionvocacional: double (nullable = true)\n",
      " |-- estu_por_tradicionfamiliar: double (nullable = true)\n",
      " |-- estu_por_influenciaalguien: double (nullable = true)\n",
      " |-- cole_bilingue: double (nullable = true)\n",
      " |-- prom_puntaje: double (nullable = true)\n",
      " |-- estu_genero_f: integer (nullable = true)\n",
      " |-- cole_calendario_a: integer (nullable = true)\n",
      " |-- cole_genero_x: integer (nullable = true)\n",
      " |-- cole_naturaleza_o: integer (nullable = true)\n",
      " |-- cole_jornada_manana: integer (nullable = true)\n",
      " |-- cole_jornada_tarde: integer (nullable = true)\n",
      " |-- cole_jornada_noche: integer (nullable = true)\n",
      " |-- cole_caracter_tecnico: integer (nullable = true)\n",
      " |-- cole_caracter_acaemico: integer (nullable = true)\n",
      " |-- cole_caracter_normalista: integer (nullable = true)\n",
      " |-- cole_nombre_sede_col_los_amigos_de_la_ciencia: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_tangareal_carretera: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_general_santander: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_ciudadela_mixta_colombia: integer (nullable = true)\n",
      " |-- cole_nombre_sede_inst_vigotsky: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_ciudadela_educativa_tumac: integer (nullable = true)\n",
      " |-- cole_nombre_sede_ie_manuel_elkin_patarrollo: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_imbili_carretera: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_san_luis_robles: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_san_jose_de_caunapi: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_liceo_nacional_max_seidel: integer (nullable = true)\n",
      " |-- cole_nombre_sede_institucion__educativa_colorado: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_misional_santa_teresita: integer (nullable = true)\n",
      " |-- cole_nombre_sede_liceo_san_andres: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_santa_teresita: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_dos_quebradas: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_manuel_benitez_duclerg: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_4_bucheli: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_iberia: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_luis_antonio_rojas_cruz: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_inmaculada_concepcion: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_inst_tec_industrial_nal_tumaco: integer (nullable = true)\n",
      " |-- cole_nombre_sede_institucion_educativa_nuevo_horizonte: integer (nullable = true)\n",
      " |-- cole_nombre_sede_i_e_roberto_mario_bischoff_-_sede_principal: integer (nullable = true)\n",
      " |-- cole_nombre_sede_instituto_gabriel_garcia_marquez: integer (nullable = true)\n",
      " |-- cole_nombre_sede_ie_llorente_-_sede_princiapl: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_faustino_arias_reinel: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_san_juan_evangelista: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_chilvi: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_inst_tec__popular_de_la_costa: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_5_colorado: integer (nullable = true)\n",
      " |-- cole_nombre_sede_inst_mixto_renacer: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_nuestra_señora_de_fatima: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_la_florida: integer (nullable = true)\n",
      " |-- cole_nombre_sede_col_rafael_pombo: integer (nullable = true)\n",
      " |-- cole_nombre_sede_sede_#_1_chajal: integer (nullable = true)\n",
      " |-- clase_final: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "\n",
    "df_ml = df_ml.withColumn(\n",
    "            \"clase_final\",  \n",
    "                        (col('clase'))\n",
    ")\n",
    "df_ml=df_ml.drop('clase')\n",
    "df_ml.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Librerias ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           variables|clase|\n",
      "+--------------------+-----+\n",
      "|[18.0,14.0,3.0,19...|    0|\n",
      "|[24.0,15.0,4.0,19...|    0|\n",
      "|[17.0,10.0,9.0,19...|    1|\n",
      "|[17.0,12.0,12.0,1...|    0|\n",
      "|[18.0,2.0,2.0,199...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['variables','clase'])\n",
    "\n",
    "df_transformed = transData(df_ml)\n",
    "df_transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|clase|count|\n",
      "+-----+-----+\n",
      "|    0| 1592|\n",
      "|    1|  331|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed.groupby('clase').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexamos las variables y la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+\n",
      "|           variables|clase|indexedClase|\n",
      "+--------------------+-----+------------+\n",
      "|[18.0,14.0,3.0,19...|    0|         0.0|\n",
      "|[24.0,15.0,4.0,19...|    0|         0.0|\n",
      "|[17.0,10.0,9.0,19...|    1|         1.0|\n",
      "|[17.0,12.0,12.0,1...|    0|         0.0|\n",
      "|[18.0,2.0,2.0,199...|    0|         0.0|\n",
      "+--------------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+--------------------+\n",
      "|           variables|clase|    indexedVariables|\n",
      "+--------------------+-----+--------------------+\n",
      "|[18.0,14.0,3.0,19...|    0|[18.0,14.0,3.0,19...|\n",
      "|[24.0,15.0,4.0,19...|    0|[24.0,15.0,4.0,19...|\n",
      "|[17.0,10.0,9.0,19...|    1|[17.0,10.0,9.0,19...|\n",
      "|[17.0,12.0,12.0,1...|    0|[17.0,12.0,12.0,1...|\n",
      "|[18.0,2.0,2.0,199...|    0|[18.0,2.0,2.0,199...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "claseIndexer = StringIndexer(inputCol='clase',\n",
    "                             outputCol='indexedClase').fit(df_transformed)\n",
    "\n",
    "# Identifique automáticamente características categóricas e indexelas.\n",
    "# Establezca maxCategories para que las entidades con> 4 valores distintos se traten como continuas.\n",
    "variablesIndexer =VectorIndexer(inputCol=\"variables\", \\\n",
    "                                  outputCol=\"indexedVariables\", \\\n",
    "                                  maxCategories=4).fit(df_transformed)\n",
    "\n",
    "claseIndexer.transform(df_transformed).show(5, True)\n",
    "variablesIndexer.transform(df_transformed).show(5, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar conjunto en train y test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           variables|clase|\n",
      "+--------------------+-----+\n",
      "|[10.0,4.0,4.0,200...|    1|\n",
      "|[10.0,6.0,1.0,200...|    0|\n",
      "|[10.0,8.0,8.0,200...|    1|\n",
      "|[10.0,12.0,7.0,19...|    1|\n",
      "|[10.0,16.0,4.0,20...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df_transformed.randomSplit([0.8, 0.2])\n",
    "trainingData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|clase|count|\n",
      "+-----+-----+\n",
      "|    0| 1287|\n",
      "|    1|  270|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|clase|count|\n",
      "+-----+-----+\n",
      "|    0|  305|\n",
      "|    1|   61|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.groupby('clase').count().show()\n",
    "testData.groupby('clase').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Train a DecisionTree model\n",
    "dTree = DecisionTreeClassifier(labelCol='indexedClase',\n",
    "                               featuresCol='indexedVariables',\n",
    "                               maxDepth = 5,\n",
    "                               minInstancesPerNode=5,\n",
    "                               impurity='entropy')\n",
    "\n",
    "# Convierta etiquetas indexadas a etiquetas originales.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\",\n",
    "                               outputCol=\"predictedLabel\",\n",
    "                               labels=claseIndexer.labels)\n",
    "\n",
    "# Canalizar el modelo mediante la tuberia \n",
    "pipeline = Pipeline(stages=[claseIndexer, variablesIndexer, dTree,\n",
    "                            labelConverter])\n",
    "\n",
    "# Esto ejecuta los indexadores y entrena el modelo. \n",
    "arbol = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"indexedClase\",\n",
    "                            featuresCol=\"indexedVariables\", \n",
    "                            numTrees=500,maxDepth = 10,\n",
    "                            minInstancesPerNode=5,\n",
    "                            impurity='entropy')\n",
    "\n",
    "# Convierta etiquetas indexadas a etiquetas originales.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=claseIndexer.labels)\n",
    "\n",
    "# Canalizar el modelo mediante la tuberia \n",
    "pipeline = Pipeline(stages=[claseIndexer, variablesIndexer, rf,\n",
    "                            labelConverter])\n",
    "# Train model.  This also runs the indexers.\n",
    "randomforest = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gradientbt = GBTClassifier(labelCol='indexedClase', \n",
    "                    featuresCol='indexedVariables',\n",
    "                    maxIter=50, maxDepth=10)\n",
    "\n",
    "# Convierta etiquetas indexadas a etiquetas originales.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=claseIndexer.labels)\n",
    "\n",
    "# Canalizar el modelo mediante la tuberia \n",
    "pipeline = Pipeline(stages=[claseIndexer, variablesIndexer, gradientbt,\n",
    "                            labelConverter])\n",
    "# Train model.  This also runs the indexers.\n",
    "gbt = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(labelCol=\"indexedClase\",featuresCol=\"indexedVariables\")\n",
    "\n",
    "# Convierta etiquetas indexadas a etiquetas originales.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=claseIndexer.labels)\n",
    "\n",
    "# Canalizar el modelo mediante la tuberia \n",
    "pipeline = Pipeline(stages=[claseIndexer, variablesIndexer, nb,\n",
    "                            labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "naivebayes = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logr = LogisticRegression(labelCol=\"indexedClase\",featuresCol=\"indexedVariables\"\n",
    "                          ,regParam=0.001)\n",
    "\n",
    "# Convierta etiquetas indexadas a etiquetas originales.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=claseIndexer.labels)\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[claseIndexer, variablesIndexer, logr,labelConverter])\n",
    "\n",
    "logregre = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# especificar capas para la red neuronal:\n",
    "# capa de entrada de tamaño 117 (características),\n",
    "# 1 capa oculta de 10\n",
    "# y salida de tamaño 2 (clases)\n",
    "layers = [91, 50 , 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "FNN = MultilayerPerceptronClassifier(labelCol=\"indexedClase\", \\\n",
    "                                     featuresCol=\"indexedVariables\",\\\n",
    "                                     maxIter=300, layers=layers, \\\n",
    "                                     blockSize=128, seed=1234)\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=claseIndexer.labels)\n",
    "# Chain indexers and forest in a Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[claseIndexer, variablesIndexer, FNN, labelConverter])\n",
    "# train the model\n",
    "# Train model.  This also runs the indexers.\n",
    "red = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluar Modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator\n",
    "from sklearn.metrics import accuracy_score,precision_score,classification_report,balanced_accuracy_score,f1_score\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "def eval_model(testData,trainingData,model,metric):\n",
    "    print(\"____________________________________\")\n",
    "    predictions_test = model.transform(testData)\n",
    "    predictions_train = model.transform(trainingData)\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedClase\", predictionCol=\"prediction\", metricName=metric)\n",
    "    accuracy_test = evaluator.evaluate(predictions_test)\n",
    "    accuracy_train = evaluator.evaluate(predictions_train)\n",
    "    print(metric+\" test = %g\" % (accuracy_test))\n",
    "    print(metric+\" train = %g\" % (accuracy_train))\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol='indexedClase')\n",
    "    \n",
    "    auroc_test = evaluator.evaluate(predictions_test,\n",
    "                               {evaluator.metricName: \"areaUnderROC\"})\n",
    "    auroc_train = evaluator.evaluate(predictions_train,\n",
    "                               {evaluator.metricName: \"areaUnderROC\"})\n",
    "    \n",
    "    print(\"AUC test = %g\" % (auroc_test))\n",
    "    print(\"AUC train = %g\" % (auroc_train))\n",
    "\n",
    "    #predictions_test=predictions_test.select('prediction').toPandas()\n",
    "    #y_test=claseIndexer.transform(testData).select(\"indexedClase\").toPandas()\n",
    "    \n",
    "    #variablesIndexer.transform(df_transformed).show(5, True)\n",
    "    #print(\"Balanced_accuracy test:\",balanced_accuracy_score(y_test[y_test.columns[0]], predictions_test[predictions_test.columns[0]]))\n",
    "    #print(\"Balanced_accuracy train:\",balanced_accuracy_score(y_train, predictions_train))\n",
    "\n",
    "    rfModel = model.stages[-2]\n",
    "    print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________\n",
      "accuracy test = 0.822404\n",
      "accuracy train = 0.850996\n",
      "AUC test = 0.496963\n",
      "AUC train = 0.448331\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_f85892cc29b0, depth=5, numNodes=31, numClasses=2, numFeatures=91\n",
      "____________________________________\n",
      "accuracy test = 0.838798\n",
      "accuracy train = 0.849069\n",
      "AUC test = 0.795216\n",
      "AUC train = 0.921687\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_815628d8c8e4, numTrees=500, numClasses=2, numFeatures=91\n",
      "____________________________________\n",
      "accuracy test = 0.79235\n",
      "accuracy train = 1\n",
      "AUC test = 0.698038\n",
      "AUC train = 1\n",
      "GBTClassificationModel: uid = GBTClassifier_252c1774469c, numTrees=50, numClasses=2, numFeatures=91\n",
      "____________________________________\n",
      "accuracy test = 0.653005\n",
      "accuracy train = 0.684008\n",
      "AUC test = 0.39613\n",
      "AUC train = 0.46919\n",
      "NaiveBayesModel: uid=NaiveBayes_180bcb1a7ba6, modelType=multinomial, numClasses=2, numFeatures=91\n",
      "____________________________________\n",
      "accuracy test = 0.822404\n",
      "accuracy train = 0.839435\n",
      "AUC test = 0.707982\n",
      "AUC train = 0.820383\n",
      "LogisticRegressionModel: uid=LogisticRegression_19bce1f94b1a, numClasses=2, numFeatures=91\n",
      "____________________________________\n",
      "accuracy test = 0.838798\n",
      "accuracy train = 0.829159\n",
      "AUC test = 0.756893\n",
      "AUC train = 0.763167\n",
      "MultilayerPerceptronClassificationModel: uid=MultilayerPerceptronClassifier_18386318518b, numLayers=3, numClasses=2, numFeatures=91\n"
     ]
    }
   ],
   "source": [
    "metricas=[\"weightedPrecision\",\"accuracy\",\"f1\",\"weightedRecall\"] \n",
    "eval_model(testData,trainingData,arbol,metricas[1])   \n",
    "eval_model(testData,trainingData,randomforest,metricas[1]) \n",
    "eval_model(testData,trainingData,gbt,metricas[1]) \n",
    "eval_model(testData,trainingData,naivebayes,metricas[1]) \n",
    "eval_model(testData,trainingData,logregre,metricas[1]) \n",
    "eval_model(testData,trainingData,red,metricas[1]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunear árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "evaluatorB = BinaryClassificationEvaluator(labelCol='indexedClase',\n",
    "                                          metricName='areaUnderROC')\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dTree.maxDepth,[5,20,15])\n",
    "             .addGrid(dTree.minInstancesPerNode,[5,2,10])\n",
    "             .addGrid(dTree.impurity,['entropy','gini'])\n",
    "             .addGrid(dTree.minInfoGain,[0.0,0.025])\n",
    "             .build())\n",
    "\n",
    "# Canalizar el modelo mediante la tuberia \n",
    "pipeline = Pipeline(stages=[claseIndexer, variablesIndexer, dTree,\n",
    "                            labelConverter])\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluatorB,\n",
    "                          numFolds=4)  # use 3+ folds in practice\n",
    "\n",
    "cvModel = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________\n",
      "accuracy test = 0.770492\n",
      "accuracy train = 0.909441\n",
      "AUC test = 0.600967\n",
      "AUC train = 0.894949\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_f85892cc29b0, depth=18, numNodes=215, numClasses=2, numFeatures=91\n",
      "20\n",
      "5\n",
      "entropy\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "arbolSummary = cvModel.bestModel\n",
    "eval_model(testData,trainingData,arbolSummary,metricas[1])  \n",
    "import numpy as np\n",
    "cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]\n",
    "print(arbolSummary.stages[2].getMaxDepth())\n",
    "print(arbolSummary.stages[2].getMinInstancesPerNode())\n",
    "print(arbolSummary.stages[2].getImpurity())\n",
    "print(arbolSummary.stages[2].getMinInfoGain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1af1fe2cbc8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(cvModel.avgMetrics, paramGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunear RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "evaluatorB = BinaryClassificationEvaluator(labelCol='indexedClase',\n",
    "                                          metricName='areaUnderROC')\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees,[500])\n",
    "             .addGrid(dTree.maxDepth,[5,7])\n",
    "             .addGrid(dTree.minInstancesPerNode,[5,3])\n",
    "             .addGrid(dTree.impurity,['entropy','gini'])\n",
    "             .addGrid(dTree.minInfoGain,[0.0,0.0025])\n",
    "             .addGrid(rf.minWeightFractionPerNode,[0.0,0.005])\n",
    "             .build())\n",
    "\n",
    "# Canalizar el modelo mediante la tuberia \n",
    "pipeline = Pipeline(stages=[claseIndexer, variablesIndexer, rf,\n",
    "                            labelConverter])\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluatorB,\n",
    "                          numFolds=4)  # use 3+ folds in practice\n",
    "\n",
    "cvModel = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________\n",
      "accuracy test = 0.833333\n",
      "accuracy train = 0.833654\n",
      "AUC test = 0.799946\n",
      "AUC train = 0.810087\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_1a07e12d30ee, numTrees=500, numClasses=2, numFeatures=91\n",
      "5\n",
      "5\n",
      "entropy\n",
      "0.005\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "rfSummary = cvModel.bestModel\n",
    "eval_model(testData,trainingData,rfSummary,metricas[1])  \n",
    "import numpy as np\n",
    "cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]\n",
    "print(rfSummary.stages[2].getMaxDepth())\n",
    "print(rfSummary.stages[2].getMinInstancesPerNode())\n",
    "print(rfSummary.stages[2].getImpurity())\n",
    "print(rfSummary.stages[2].getMinWeightFractionPerNode())\n",
    "print(rfSummary.stages[2].getMinInfoGain())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
